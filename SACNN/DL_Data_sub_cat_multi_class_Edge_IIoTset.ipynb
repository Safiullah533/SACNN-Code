{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import time\n",
    "import regex\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"G:\\Datasets\\Edge-IIoTset dataset\\Selected dataset for ML and DL\\DNN-EdgeIIoT-dataset.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max.rows\", None)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.sample(frac = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Attack_type'] = label_encoder.fit_transform(df['Attack_type'])\n",
    "df['Attack_type'] = df['Attack_type'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df.columns:\n",
    "    if(df[i].dtypes == object):\n",
    "        df[i] = label_encoder.fit_transform(df[i])\n",
    "        df[i] = df[i].astype(float)\n",
    "    print(df[i].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['Attack_type','Attack_label'])\n",
    "y = df['Attack_label']\n",
    "y1 = df['Attack_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ExtraTreesClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in model.feature_importances_:\n",
    "    if i <= 0:\n",
    "        print('ok')\n",
    "print(model.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_importances = pd.Series(model.feature_importances_, index=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_importances.nlargest(80).plot(kind='barh',figsize=(20, 15))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the following attributes are already identified to be drop in DL_Data_sub_cat_multi_class_Edge_IIoTset.ipynb using feature selection method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=X.drop(columns=['icmp.transmit_timestamp','icmp.unused','http.tls_port','dns.qry.type','mqtt.msg_decoded_as','mbtcp.len','mbtcp.unit_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalization of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=((X-X.min())/(X.max()-X.min()))*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X, dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.reshape(2219201, 54, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y1, test_size=0.2,stratify=y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import time\n",
    "import regex\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM, GRU, RNN, SimpleRNN\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import seaborn as sn\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import keras\n",
    "from keras.layers import Convolution1D, Dense, Dropout, Flatten, MaxPooling1D , AveragePooling1D\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM, GRU\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import tensorflow as tf\n",
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import make_scorer\n",
    "from scipy.stats import zscore\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################\n",
    "###########################################\n",
    "##\n",
    "##      Proposed Model----- Self-Attention CNN\n",
    "##\n",
    "############################################\n",
    "###########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = X.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 cn+ 1pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proposed_model():\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(inputs)\n",
    "    x = layers.MultiHeadAttention(key_dim=7, num_heads=8)(x, x)\n",
    "\n",
    "    res = x + inputs\n",
    "    x = layers.Conv1D(26, 3, activation=\"relu\")(res)\n",
    "    x = layers.MaxPooling1D(pool_size=(4))(x)\n",
    "\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(32, activation=\"relu\")(x)\n",
    "    x = layers.Dense(15, activation=\"softmax\")(x)\n",
    "\n",
    "    return keras.Model(inputs, x)\n",
    "\n",
    "\n",
    "model = proposed_model()\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train, epochs = 6).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_df = pd.DataFrame(history) \n",
    "\n",
    "# and save to csv: \n",
    "hist_csv_file = 'G:/Training Results/proposed/1cn1pl.csv'\n",
    "with open(hist_csv_file, mode='w') as f:\n",
    "    hist_df.to_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vd_preds_G = model.predict(X_test).argmax(axis=1)\n",
    "con_G=confusion_matrix(y_test, vd_preds_G)\n",
    "print(con_G)\n",
    "print(\"Precision: \",precision_score(y_test,vd_preds_G,average='macro'))\n",
    "print(\"Recall: \", recall_score(y_test,vd_preds_G,average='macro'))\n",
    "print(\"F1-score: \", f1_score(y_test,vd_preds_G,average='macro'))\n",
    "print(\"Accuracy: \", accuracy_score(y_test,vd_preds_G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 cn+ 1pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proposed_model():\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(inputs)\n",
    "    x = layers.MultiHeadAttention(key_dim=7, num_heads=8)(x, x)\n",
    "\n",
    "    res = x + inputs\n",
    "    x = layers.Conv1D(26, 3, activation=\"relu\")(res)\n",
    "    x = layers.Conv1D(25, 3, activation=\"relu\")(x)\n",
    "    x = layers.MaxPooling1D(pool_size=(4))(x)\n",
    "\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(32, activation=\"relu\")(x)\n",
    "    x = layers.Dense(15, activation=\"softmax\")(x)\n",
    "\n",
    "    return keras.Model(inputs, x)\n",
    "\n",
    "\n",
    "model = proposed_model()\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train, epochs = 6).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_df = pd.DataFrame(history) \n",
    "\n",
    "# and save to csv: \n",
    "hist_csv_file = 'G:/Training Results/proposed/2cn1pl.csv'\n",
    "with open(hist_csv_file, mode='w') as f:\n",
    "    hist_df.to_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vd_preds_G = model.predict(X_test).argmax(axis=1)\n",
    "\n",
    "print(\"Precision: \",precision_score(y_test,vd_preds_G,average='macro'))\n",
    "print(\"Recall: \", recall_score(y_test,vd_preds_G,average='macro'))\n",
    "print(\"F1-score: \", f1_score(y_test,vd_preds_G,average='macro'))\n",
    "print(\"Accuracy: \", accuracy_score(y_test,vd_preds_G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 cn+ 2pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proposed_model():\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(inputs)\n",
    "    x = layers.MultiHeadAttention(key_dim=7, num_heads=8)(x, x)\n",
    "\n",
    "    res = x + inputs\n",
    "    x = layers.Conv1D(27, 3, activation=\"relu\")(res)\n",
    "    x = layers.MaxPooling1D(pool_size=(4))(x)\n",
    "\n",
    "    x = layers.Conv1D(14, 3, activation=\"relu\")(x)\n",
    "    x = layers.MaxPooling1D(pool_size=(2))(x)\n",
    "\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(30, activation=\"relu\")(x)\n",
    "    x = layers.Dense(15, activation=\"softmax\")(x)\n",
    "\n",
    "    return keras.Model(inputs, x)\n",
    "\n",
    "\n",
    "model = proposed_model()\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs = 6).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_df = pd.DataFrame(history) \n",
    "\n",
    "# and save to csv: \n",
    "hist_csv_file = 'G:/Training Results/proposed/2cn2pl.csv'\n",
    "with open(hist_csv_file, mode='w') as f:\n",
    "    hist_df.to_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vd_preds_G = model.predict(X_test).argmax(axis=1)\n",
    "con_G=confusion_matrix(y_test, vd_preds_G)\n",
    "print(con_G)\n",
    "print(\"Precision: \",precision_score(y_test,vd_preds_G,average='macro'))\n",
    "print(\"Recall: \", recall_score(y_test,vd_preds_G,average='macro'))\n",
    "print(\"F1-score: \", f1_score(y_test,vd_preds_G,average='macro'))\n",
    "print(\"Accuracy: \", accuracy_score(y_test,vd_preds_G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 cn+ 2pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proposed_model():\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(inputs)\n",
    "    x = layers.MultiHeadAttention(key_dim=7, num_heads=8)(x, x)\n",
    "\n",
    "    res = x + inputs\n",
    "    x = layers.Conv1D(26, 3, activation=\"relu\")(res)\n",
    "    x = layers.Conv1D(25, 3, activation=\"relu\")(x)\n",
    "    x = layers.MaxPooling1D(pool_size=(4))(x)\n",
    "\n",
    "    x = layers.Conv1D(10, 3, activation=\"relu\")(x)\n",
    "    x = layers.Conv1D(8, 3, activation=\"relu\")(x)\n",
    "    x = layers.MaxPooling1D(pool_size=(2))(x)\n",
    "\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(32, activation=\"relu\")(x)\n",
    "    x = layers.Dense(15, activation=\"softmax\")(x)\n",
    "\n",
    "    return keras.Model(inputs, x)\n",
    "\n",
    "\n",
    "model = proposed_model()\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, epochs = 6).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_df = pd.DataFrame(history) \n",
    "\n",
    "# and save to csv: \n",
    "hist_csv_file = 'G:/Training Results/proposed/4cn2pl.csv'\n",
    "with open(hist_csv_file, mode='w') as f:\n",
    "    hist_df.to_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vd_preds_G = model.predict(X_test).argmax(axis=1)\n",
    "\n",
    "print(\"Precision: \",precision_score(y_test,vd_preds_G,average='macro'))\n",
    "print(\"Recall: \", recall_score(y_test,vd_preds_G,average='macro'))\n",
    "print(\"F1-score: \", f1_score(y_test,vd_preds_G,average='macro'))\n",
    "print(\"Accuracy: \", accuracy_score(y_test,vd_preds_G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
